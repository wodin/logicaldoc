<?xml version="1.0" encoding="UTF-8" ?>
<!-- Avoid spellchecking during JUnit tests -->
<config>
	<abortOnConfigurationError>${solr.abortOnConfigurationError:true}
	</abortOnConfigurationError>
	<luceneMatchVersion>LUCENE_35</luceneMatchVersion>
	<dataDir>${solr.data.dir:}</dataDir>	
	<directoryFactory name="DirectoryFactory"
		class="${solr.directoryFactory:solr.StandardDirectoryFactory}" />
	<indexDefaults>
	    <unlockOnStartup>true</unlockOnStartup>
		
		<useCompoundFile>false</useCompoundFile>

		<mergeFactor>10</mergeFactor>
		<!-- Sets the amount of RAM that may be used by Lucene indexing for buffering 
			added documents and deletions before they are flushed to the Directory. -->
		<ramBufferSizeMB>32</ramBufferSizeMB>
		<!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will 
			flush based on whichever limit is hit first. -->
		<!-- <maxBufferedDocs>1000</maxBufferedDocs> -->

		<maxFieldLength>10000</maxFieldLength>
		<writeLockTimeout>1000</writeLockTimeout>

		<!-- Expert: Merge Policy The Merge Policy in Lucene controls how merging 
			is handled by Lucene. The default in Solr 3.3 is TieredMergePolicy. The default 
			in 2.3 was the LogByteSizeMergePolicy, previous versions used LogDocMergePolicy. 
			LogByteSizeMergePolicy chooses segments to merge based on their size. The 
			Lucene 2.2 default, LogDocMergePolicy chose when to merge based on number 
			of documents Other implementations of MergePolicy must have a no-argument 
			constructor -->
		<!-- <mergePolicy class="org.apache.lucene.index.TieredMergePolicy"/> -->

		<!-- Expert: Merge Scheduler The Merge Scheduler in Lucene controls how 
			merges are performed. The ConcurrentMergeScheduler (Lucene 2.3 default) can 
			perform merges in the background using separate threads. The SerialMergeScheduler 
			(Lucene 2.2 default) does not. -->
		<!-- <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler"/> -->

		<!-- LockFactory This option specifies which Lucene LockFactory implementation 
			to use. single = SingleInstanceLockFactory - suggested for a read-only index 
			or when there is no possibility of another process trying to modify the index. 
			native = NativeFSLockFactory - uses OS native file locking. Do not use when 
			multiple solr webapps in the same JVM are attempting to share a single index. 
			simple = SimpleFSLockFactory - uses a plain file for locking (For backwards 
			compatibility with Solr 1.2, 'simple' is the default if not specified.) More 
			details on the nuances of each LockFactory... http://wiki.apache.org/lucene-java/AvailableLockFactories -->
		<lockType>native</lockType>

		<!-- Expert: Controls how often Lucene loads terms into memory Default 
			is 128 and is likely good for most everyone. -->
		<!-- <termIndexInterval>256</termIndexInterval> -->
	</indexDefaults>

	<!-- Main Index Values here override the values in the <indexDefaults> section 
		for the main on disk index. -->
	<mainIndex>
		<useCompoundFile>false</useCompoundFile>
		<ramBufferSizeMB>32</ramBufferSizeMB>
		<mergeFactor>10</mergeFactor>

		<!-- Unlock On Startup If true, unlock any held write or commit locks on 
			startup. This defeats the locking mechanism that allows multiple processes 
			to safely access a lucene index, and should be used with care. This is not 
			needed if lock type is 'none' or 'single' -->
		<unlockOnStartup>true</unlockOnStartup>

		<!-- If true, IndexReaders will be reopened (often more efficient) instead 
			of closed and then opened. -->
		<reopenReaders>true</reopenReaders>

		<!-- Commit Deletion Policy Custom deletion policies can specified here. 
			The class must implement org.apache.lucene.index.IndexDeletionPolicy. http://lucene.apache.org/java/2_9_1/api/all/org/apache/lucene/index/IndexDeletionPolicy.html 
			The standard Solr IndexDeletionPolicy implementation supports deleting index 
			commit points on number of commits, age of commit point and optimized status. 
			The latest commit point should always be preserved regardless of the criteria. -->
		<deletionPolicy class="solr.SolrDeletionPolicy">
			<!-- The number of commit points to be kept -->
			<str name="maxCommitsToKeep">1</str>
			<!-- The number of optimized commit points to be kept -->
			<str name="maxOptimizedCommitsToKeep">0</str>
			<!-- Delete all commit points once they have reached the given age. Supports 
				DateMathParser syntax e.g. -->
			<!-- <str name="maxCommitAge">30MINUTES</str> <str name="maxCommitAge">1DAY</str> -->
		</deletionPolicy>

		<!-- Lucene Infostream To aid in advanced debugging, Lucene provides an 
			"InfoStream" of detailed information when indexing. Setting The value to 
			true will instruct the underlying Lucene IndexWriter to write its debugging 
			info the specified file -->
		<infoStream file="INFOSTREAM.txt">false</infoStream>

	</mainIndex>

	<jmx />

	<!-- The default high-performance update handler -->
	<updateHandler class="solr.DirectUpdateHandler2">
		<autoCommit>
			<maxDocs>500</maxDocs>
			<maxTime>1000</maxTime>
		</autoCommit>


		<!-- Update Related Event Listeners Various IndexWriter related events 
			can trigger Listeners to take actions. postCommit - fired after every commit 
			or optimize command postOptimize - fired after every optimize command -->
		<!-- The RunExecutableListener executes an external command from a hook 
			such as postCommit or postOptimize. exe - the name of the executable to run 
			dir - dir to use as the current working directory. (default=".") wait - the 
			calling thread waits until the executable returns. (default="true") args 
			- the arguments to pass to the program. (default is none) env - environment 
			variables to set. (default is none) -->
		<!-- This example shows how RunExecutableListener could be used with the 
			script based replication... http://wiki.apache.org/solr/CollectionDistribution -->
		<!-- <listener event="postCommit" class="solr.RunExecutableListener"> <str 
			name="exe">solr/bin/snapshooter</str> <str name="dir">.</str> <bool name="wait">true</bool> 
			<arr name="args"> <str>arg1</str> <str>arg2</str> </arr> <arr name="env"> 
			<str>MYVAR=val1</str> </arr> </listener> -->
	</updateHandler>


	<query>
		<maxBooleanClauses>1024</maxBooleanClauses>


		<!-- Solr Internal Query Caches There are two implementations of cache 
			available for Solr, LRUCache, based on a synchronized LinkedHashMap, and 
			FastLRUCache, based on a ConcurrentHashMap. FastLRUCache has faster gets 
			and slower puts in single threaded operation and thus is generally faster 
			than LRUCache when the hit ratio of the cache is high (> 75%), and may be 
			faster under other scenarios on multi-cpu systems. -->

		<!-- Filter Cache Cache used by SolrIndexSearcher for filters (DocSets), 
			unordered sets of *all* documents that match a query. When a new searcher 
			is opened, its caches may be prepopulated or "autowarmed" using data from 
			caches in the old searcher. autowarmCount is the number of items to prepopulate. 
			For LRUCache, the autowarmed items will be the most recently accessed items. 
			Parameters: class - the SolrCache implementation LRUCache or (LRUCache or 
			FastLRUCache) size - the maximum number of entries in the cache initialSize 
			- the initial capacity (number of entries) of the cache. (see java.util.HashMap) 
			autowarmCount - the number of entries to prepopulate from and old cache. -->
		<filterCache class="solr.FastLRUCache" size="512"
			initialSize="512" autowarmCount="0" />

		<!-- Query Result Cache Caches results of searches - ordered lists of document 
			ids (DocList) based on a query, a sort, and the range of documents requested. -->
		<queryResultCache class="solr.LRUCache" size="512"
			initialSize="512" autowarmCount="0" />

		<!-- Document Cache Caches Lucene Document objects (the stored fields for 
			each document). Since Lucene internal document ids are transient, this cache 
			will not be autowarmed. -->
		<documentCache class="solr.LRUCache" size="512"
			initialSize="512" autowarmCount="0" />

		<!-- Field Value Cache Cache used to hold field values that are quickly 
			accessible by document id. The fieldValueCache is created by default even 
			if not configured here. -->
		<!-- <fieldValueCache class="solr.FastLRUCache" size="512" autowarmCount="128" 
			showItems="32" /> -->


		<!-- Lazy Field Loading If true, stored fields that are not requested will 
			be loaded lazily. This can result in a significant speed improvement if the 
			usual case is to not load all stored fields, especially if the skipped fields 
			are large compressed text fields. -->
		<enableLazyFieldLoading>true</enableLazyFieldLoading>

		<!-- Use Filter For Sorted Query A possible optimization that attempts 
			to use a filter to satisfy a search. If the requested sort does not include 
			score, then the filterCache will be checked for a filter matching the query. 
			If found, the filter will be used as the source of document ids, and then 
			the sort will be applied to that. For most situations, this will not be useful 
			unless you frequently get the same search repeatedly with different sort 
			options, and none of them ever use "score" -->
		<!-- <useFilterForSortedQuery>true</useFilterForSortedQuery> -->

		<!-- Result Window Size An optimization for use with the queryResultCache. 
			When a search is requested, a superset of the requested number of document 
			ids are collected. For example, if a search for a particular query requests 
			matching documents 10 through 19, and queryWindowSize is 50, then documents 
			0 through 49 will be collected and cached. Any further requests in that range 
			can be satisfied via the cache. -->
		<queryResultWindowSize>20</queryResultWindowSize>

		<!-- Maximum number of documents to cache for any entry in the queryResultCache. -->
		<queryResultMaxDocsCached>200</queryResultMaxDocsCached>

		<!-- Query Related Event Listeners Various IndexSearcher related events 
			can trigger Listeners to take actions. newSearcher - fired whenever a new 
			searcher is being prepared and there is a current searcher handling requests 
			(aka registered). It can be used to prime certain caches to prevent long 
			request times for certain requests. firstSearcher - fired whenever a new 
			searcher is being prepared but there is no current registered searcher to 
			handle requests or to gain autowarming data from. -->


		<!-- Use Cold Searcher If a search request comes in and there is no current 
			registered searcher, then immediately register the still warming searcher 
			and use it. If "false" then all requests will block until the first searcher 
			is done warming. -->
		<useColdSearcher>false</useColdSearcher>

		<!-- Max Warming Searchers Maximum number of searchers that may be warming 
			in the background concurrently. An error is returned if this limit is exceeded. 
			Recommend values of 1-2 for read-only slaves, higher for masters w/o cache 
			warming. -->
		<maxWarmingSearchers>2</maxWarmingSearchers>
	</query>


	<!-- Request Dispatcher This section contains instructions for how the SolrDispatchFilter 
		should behave when processing requests for this SolrCore. handleSelect affects 
		the behavior of requests such as /select?qt=XXX handleSelect="true" will 
		cause the SolrDispatchFilter to process the request and will result in consistent 
		error handling and formatting for all types of requests. handleSelect="false" 
		will cause the SolrDispatchFilter to ignore "/select" requests and fallback 
		to using the legacy SolrServlet and it's Solr 1.1 style error formatting -->
	<requestDispatcher handleSelect="true">
		<!-- Request Parsing These settings indicate how Solr Requests may be parsed, 
			and what restrictions may be placed on the ContentStreams from those requests 
			enableRemoteStreaming - enables use of the stream.file and stream.url parameters 
			for specifying remote streams. multipartUploadLimitInKB - specifies the max 
			size of Multipart File Uploads that Solr will allow in a Request. *** WARNING 
			*** The settings below authorize Solr to fetch remote files, You should make 
			sure your system has some authentication before using enableRemoteStreaming="true" -->
		<requestParsers enableRemoteStreaming="true"
			multipartUploadLimitInKB="2048000" />

		<!-- HTTP Caching Set HTTP caching related parameters (for proxy caches 
			and clients). The options below instruct Solr not to output any HTTP Caching 
			related headers -->
		<httpCaching never304="true" />
		<!-- If you include a <cacheControl> directive, it will be used to generate 
			a Cache-Control header (as well as an Expires header if the value contains 
			"max-age=") By default, no Cache-Control header is generated. You can use 
			the <cacheControl> option even if you have set never304="true" -->
		<!-- <httpCaching never304="true" > <cacheControl>max-age=30, public</cacheControl> 
			</httpCaching> -->
		<!-- To enable Solr to respond with automatically generated HTTP Caching 
			headers, and to response to Cache Validation requests correctly, set the 
			value of never304="false" This will cause Solr to generate Last-Modified 
			and ETag headers based on the properties of the Index. The following options 
			can also be specified to affect the values of these headers... lastModFrom 
			- the default value is "openTime" which means the Last-Modified value (and 
			validation against If-Modified-Since requests) will all be relative to when 
			the current Searcher was opened. You can change it to lastModFrom="dirLastMod" 
			if you want the value to exactly correspond to when the physical index was 
			last modified. etagSeed="..." is an option you can change to force the ETag 
			header (and validation against If-None-Match requests) to be different even 
			if the index has not changed (ie: when making significant changes to your 
			config file) (lastModifiedFrom and etagSeed are both ignored if you use the 
			never304="true" option) -->
		<!-- <httpCaching lastModifiedFrom="openTime" etagSeed="Solr"> <cacheControl>max-age=30, 
			public</cacheControl> </httpCaching> -->
	</requestDispatcher>

	<requestHandler name="search" class="solr.SearchHandler"
		default="true">
		<lst name="defaults">
			<str name="spellcheck.dictionary">default</str>
			<str name="spellcheck.onlyMorePopular">false</str>
			<str name="spellcheck.extendedResults">false</str>
			<str name="spellcheck.count">1</str>
			<str name="spellcheck.collate">true</str>
			<str name="spellcheck.maxCollationTries">1</str>
            <str name="spellcheck">true</str>			
			<str name="rows">500</str>
		</lst>

		<arr name="components">
			<str>query</str>
			<!-- str>facet</str> <str>mlt</str -->
			<str>highlight</str>
			<!-- str>spellcheck</str -->
			<!-- str>stats</str> <str>debug</str -->
		</arr>
	</requestHandler>

	<requestHandler name="/update" class="solr.XmlUpdateRequestHandler">
		<lst name="defaults">
			<str name="update.chain">language</str>
		</lst>
	</requestHandler>


	<!-- Highlighting Component -->
	<searchComponent class="solr.HighlightComponent" name="highlight">
		<highlighting>
			<fragmenter name="regex" class="solr.highlight.RegexFragmenter"
				default="true">
				<lst name="defaults">
					<!-- slightly smaller fragsizes work better because of slop -->
					<int name="hl.fragsize">70</int>
					<!-- allow 50% slop on fragment sizes -->
					<float name="hl.regex.slop">0.5</float>
					<!-- a basic sentence pattern -->
					<str name="hl.regex.pattern">[-\w ,/\n\&quot;&apos;]{20,200}</str>
				</lst>
			</fragmenter>

			<formatter name="html" default="true"
				class="solr.highlight.HtmlFormatter">
				<lst name="defaults">
					<str name="hl.simple.pre"><![CDATA[<font style='background-color:#FFFF00'>]]></str>
					<str name="hl.simple.post"><![CDATA[</font>]]></str>
				</lst>
			</formatter>

			<encoder name="html" class="solr.highlight.HtmlEncoder"
				default="true" />
		</highlighting>
	</searchComponent>

	<updateRequestProcessorChain name="language">
		<processor class="com.logicaldoc.core.searchengine.LanguageProcessorFactory" />
		<processor class="solr.LogUpdateProcessorFactory" />
		<processor class="solr.RunUpdateProcessorFactory" />
	</updateRequestProcessorChain>
</config>